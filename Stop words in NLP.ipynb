{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwYq6Bb5-nd7"
      },
      "outputs": [],
      "source": [
        "#what is stopwords\n",
        "\"\"\"What are stopwords they are nothing but the words being used more often having a lowimpact in our NLP process.\n",
        " E.g there are many words in the text we provide for our NLPtraining which will cause no impact in our training but to waste extra\n",
        " computation powerfor example ‘a’ this word is used very often an in some documents\n",
        " it might have beenused 100 times but that won’t help us to train or gain better accuracy in our NLP hencewe filter out these words before training.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9zbABN_WCY",
        "outputId": "05c5b238-3080-4026-b143-c3b9ba95b02e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform standard imports for NLTK:\n",
        "from nltk.corpus import stopwords\n",
        "nltkk=stopwords.words('english')"
      ],
      "metadata": {
        "id": "NmnYPB3O_sNz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nltkk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU4UvSa4AohW",
        "outputId": "d1265c13-4a1a-467c-8822-575d39e4b5c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform standard imports for Spacy:\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebYUlbjEAJQz",
        "outputId": "abe9686f-49d5-4134-d95c-eb63143465a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph=\"Stop words are those words that do not contribute to the deeper meaning of the phrase. They are the most common words such as: the, a, and is. For some applications like documentation classification, it may make sense to remove stop words. NLTK provides a list of commonly agreed upon stop words for a variety of languages, such as English..\""
      ],
      "metadata": {
        "id": "CXAQLzNOBOri"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Doing tokenization process for a paragraph\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer=PorterStemmer()\n",
        "nltk.download('punkt')\n",
        "sentences=nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WpciA4YBS63",
        "outputId": "5b3b6d83-0fe7-4b68-f862-228c564e04a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#orginal sentences\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ3Tf4_gDFic",
        "outputId": "e310d36d-e0b2-46d9-dd4c-7bb129fd6657"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Stop words are those words that do not contribute to the deeper meaning of the phrase.',\n",
              " 'They are the most common words such as: the, a, and is.',\n",
              " 'For some applications like documentation classification, it may make sense to remove stop words.',\n",
              " 'NLTK provides a list of commonly agreed upon stop words for a variety of languages, such as English..']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply stopwords and filter and apply stemming/lemitization\n",
        "# Processing sentences\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [stemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
        "    sentences[i] = ' '.join(words)\n",
        "\n",
        "# Modified sentences\n",
        "print(\"\\nModified Sentences:\")\n",
        "for sentence in sentences:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUq48H_UC3Gj",
        "outputId": "0064a7d1-a501-4dd5-8499-17da303aacb3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modified Sentences:\n",
            "stop word word contribut deeper mean phrase .\n",
            "common word : , , .\n",
            "applic like document classif , may make sen remov stop word .\n",
            "nltk provid list commonli agr upon stop word varieti languag , english ..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "# Processing sentences\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
        "    sentences[i] = ' '.join(words)\n",
        "\n",
        "# Modified sentences\n",
        "print(\"\\nModified Sentences:\")\n",
        "for sentence in sentences:\n",
        "    print(sentence)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAPrbieJF7j5",
        "outputId": "33ca2f63-4573-4cd3-b8d5-c1a9e5807b7f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modified Sentences:\n",
            "stop word word contribut deeper mean phrase .\n",
            "common word : , , .\n",
            "applic like document classif , may make sen remov stop word .\n",
            "nltk provid list commonli agr upon stop word varieti languag , english ..\n"
          ]
        }
      ]
    }
  ]
}