{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRosmGQ5FS5_",
        "outputId": "15bf42a8-b14f-4ec5-aa94-1d028338d282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRP'), ('am', 'VBP'), ('learning', 'VBG'), ('NLP', 'NNP'), ('in', 'IN'), ('Python', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "sentence = \"I am learning NLP in Python\"\n",
        "nltk.download('punkt')\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Abbreviation Meaning\n",
        "CC coordinating conjunction\n",
        "CD cardinal digit\n",
        "DT determiner\n",
        "EX existential there\n",
        "FW foreign word\n",
        "IN preposition/subordinating conjunction\n",
        "JJ This NLTK POS Tag is an adjective (large)\n",
        "JJR adjective, comparative (larger)\n",
        "JJS adjective, superlative (largest)\n",
        "LS list market\n",
        "MD modal (could, will)\n",
        "NN noun, singular (cat, tree)\n",
        "NNS noun plural (desks)\n",
        "NNP proper noun, singular (sarah)\n",
        "NNPS proper noun, plural (indians or americans)\n",
        "PDT predeterminer (all, both, half)\n",
        "POS possessive ending (parent\\ â€˜s)\n",
        "PRP personal pronoun (hers, herself, him, himself)\n",
        "PRP$ possessive pronoun (her, his, mine, my, our )\n",
        "RB adverb (occasionally, swiftly)\n",
        "RBR adverb, comparative (greater)\n",
        "RBS adverb, superlative (biggest)\n",
        "RP particle (about)\n",
        "TO infinite marker (to)\n",
        "UH interjection (goodbye)\n",
        "VB verb (ask)\n",
        "VBG verb gerund (judging)\n",
        "VBD verb past tense (pleaded)\n",
        "VBN verb past participle (reunified)\n",
        "VBP verb, present tense not 3rd person singular(wrap)\n",
        "VBZ verb, present tense with 3rd person singular (bases)\n",
        "WDT wh-determiner (that, what)\n",
        "WP wh- pronoun (who)\n",
        "WRB wh- adverb (how) \"\"\""
      ],
      "metadata": {
        "id": "OINd-IloHHCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph=\"TextBlob is a useful library for conveniently performing everyday NLP tasks.such as POS tagging, noun phrase extraction, sentiment analysis, etc. It is built on top of NLTK and provides a simple and easy-to-use API.\""
      ],
      "metadata": {
        "id": "PXUIicTTHNRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting paragraph to sentences\n",
        "from nltk.corpus import stopwords\n",
        "sentences=nltk.sent_tokenize(paragraph)\n"
      ],
      "metadata": {
        "id": "k5SfiI3oHTy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I_YL5TxH2nZ",
        "outputId": "56ff8ba3-6866-44ce-a592-48679134951f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TextBlob is a useful library for conveniently performing everyday NLP tasks.such as POS tagging, noun phrase extraction, sentiment analysis, etc.',\n",
              " 'It is built on top of NLTK and provides a simple and easy-to-use API.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing a library\n",
        "aper=nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TDVgOrJH545",
        "outputId": "0ca880b8-0783-48f6-a6a6-3b0924ecaac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we will find the Pos tag\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Assuming you have 'sentences' defined somewhere\n",
        "\n",
        "# Download stopwords if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Initialize an empty list to store the POS tagged words\n",
        "pos_tags = []\n",
        "\n",
        "# Iterate over each sentence\n",
        "for sentence in sentences:\n",
        "    # Tokenize the sentence into words\n",
        "    words = nltk.word_tokenize(sentence)\n",
        "\n",
        "    # Remove stopwords from the words list\n",
        "    words = [word for word in words if word.lower() not in set(stopwords.words('english'))]\n",
        "\n",
        "    # Perform POS tagging on the remaining words\n",
        "    pos_tag = nltk.pos_tag(words)\n",
        "\n",
        "    # Extend the pos_tags list with the tagged words\n",
        "    pos_tags.extend(pos_tag)\n",
        "\n",
        "# Print the POS tagged words\n",
        "print(pos_tags)\n",
        "#this will give individual word to word parts of speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8bgs4MpIcxB",
        "outputId": "0ec59fc1-17a7-4b5e-b2a3-3ed874198b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('TextBlob', 'NNP'), ('useful', 'JJ'), ('library', 'NN'), ('conveniently', 'RB'), ('performing', 'VBG'), ('everyday', 'JJ'), ('NLP', 'NNP'), ('tasks.such', 'JJ'), ('POS', 'NNP'), ('tagging', 'NN'), (',', ','), ('noun', 'JJ'), ('phrase', 'NN'), ('extraction', 'NN'), (',', ','), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.'), ('built', 'VBN'), ('top', 'JJ'), ('NLTK', 'NNP'), ('provides', 'VBZ'), ('simple', 'JJ'), ('easy-to-use', 'JJ'), ('API', 'NNP'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}